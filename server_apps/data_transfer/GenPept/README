##################################################################
 
  README for fetch_load_GenPept.sh
 
##################################################################

------------------------------------------------------------------
  ZFIN Objective:
------------------------------------------------------------------

To extract relationships from GenPept files that can be used to 
create Protien sequence links for Zebrafish genes.

Nov 2003: Objective refinement, we now want to filter out GenPept 
when more than one is associated with a nt-accession.

Dec 2003: Objective refinement, we now want to add back the specific
GenPept(s) accociated with a particular gene when the gene is 
contained in a streach of genomic DNA. 
this requires more data than proteins and the nt-seq from which the 
protein was derived. We are now also capturing the gene "name" from
the GenPept record and using it to narrow the feild.
  
------------------------------------------------------------------
  Data Files:
------------------------------------------------------------------  

GenBank hosts individual GenPept records on their Entrez Web site. 

ZFIN is interested in:
all zebrafish protien acessions and the acessions of neculotide
sequences from which the protiens were derived. As well as the name(s)
if any given to the gene in the GenBank/GenPept Records


------------------------------------------------------------------
  Procedure:
------------------------------------------------------------------ 
Curators supply a list of genes and GenPepts we want in with 
manual curation attribution (so the automatic load does not delete them)

these are loaded into ZFIN from the list in 'manual_curation.genpept'
with the 'load_manual_genpept.sql' script. (called by 'fetch_load_GenPept.sh') 

DOWNLOADING
Using fetch-genpept.pl , the most recent GenPept records are 
dowloaded from NCBI's Entrez page. The fetch script is written
to download the data in chunks, however the current implementation
downloads all records in one request. 

The ~20Meg http stream is parsed into a ~200k Informix load file
by parse-genpept.r.

the genpept links are inserted into the database with the 
load_refseq.sql script  via dbaccess. This process is automated to 
perform weekly in crontab.
