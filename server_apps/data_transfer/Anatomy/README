=======================================================
== README for data_transfer/Anatomy
=======================================================

This directory has a group of scripts for unload the AO from ZFIN to OBO file,
and a group of scripts for load the OBO file back into ZFIN to update the AO.

---------------------------------------------------
-- Unload AO
--------------------------------------------------

Scripts:
--------
  err_report.pl -- function reportErr($)

  anatitem_2_obo.pl -- unload anatomy and anatomy relationship to a obo file.

  stg_2_obo.pl -- unload stage information to a obo file.

  unloadAO.pl  -- master script. Generate and send zfin.obo to <!--|AO_EMAIL_CURATOR|-->, error to <!--|AO_EMAIL_ERR|-->

Execution:
----------
  To generate OBO for curators

	% gmake unload
     
  To generate OBO for OBO site
	
	% gmake unloadshare

  With both execution, the OBO file would be emailed to curators. Curators would re-save them in DagEdit to re-order the items, and commit the internal version into CVS, and send the external one to OBO site and collaborators. 

---------------------------------------------------
-- Load AO
--------------------------------------------------

Scripts:
--------

   parseOBO.pl -- parser, generates the .unl files for loading

   loadAO.sql -- big SQL, prepare and load AO to ZFIN. 

   make_annot_translation.sql -- unload AO_translation.unl, launch
			batch_xpat_annot_adjust() function.

   batch_xpat_annot_adjust.pl -- execute xpat_annot_adjust() function on 
			each row in anatitem_stg_change_tmp table.

   parse_stage_keywords.pl -- reads stageKeywords.csv from Thisse template,
			parse it into stageKeywords.unl for loading.

   check_thisse_keywords.sql -- pick up stageKeywords.unl, output problem
                        keywords after ZFIN AO got updated. 

   check_annotation.sql   -- check the expression annotation stage window 
                        with the anatomy stage window, output inconsistences to 
                        annotationViolates.err

   loadMaster.sh -- launch the load, then ajust xpat annotation, check Thisse
		    template and send problems to curators.		    
   
Execution:
----------

   It would be nice to automate this process, and just type "gmake load" and done, however, the free human editing in DAG edit or OBO edit is not going to be error free, which means testing is always needed.  

   1) Get the up-to-date anatomy.obo file from CVS project "Curation"

   2) Parse
      At a fresh test db, clean and re-gmake the Target dir for server_apps/data_transfer/Anatomy,
      copy over the anatomy.obo file. The file is normally in MS format, do the conversion first:

        % tr -d '\r' < anatomy.obo >! anatomy.obo.new
        % mv anatomy.obo.new anatomy.obo

  	% parseOBO.pl anatomy.obo

     Check STDOUT for error. Fix the local anaotmy.obo. (we will commit it back to cvs at the end of the load.)
     
   3) Test load 
     At TARGET dir, open loadAO.sql, COMMENT OUT "commit work", 
     it would be a good idea to comment out the "verfiy XPAT annotation" 
     part for the first couple test run of loadAO.sql. The reason is, 
     we always find something that need the curators to make adjustment,
     and this last verification sql executes for long, we don't need to wait 
     for that when there were other error to fix first. 

	% dbaccess <db_name> loadAO.sql

     Check that
     o No SQL error. 

     o ls -l *.err
       check pub_incorrect.err, start_startInconsistent.err, 
       end_startInconsistent.err, end_endInconsistent.err, and 
       obsolete_anat_with_xpat.err. Send the error report to curators,
       After the corrections are made, repeat the parsing and test-loading.

     After the above errors are all fixed, uncomment the sql for
     annotation violation check. Run the loading again and send 
     annotationViolates.err content to Ceri & Melissa, 
     Ask for 
     o  AO_translation.unl with format

        ZFA:####|start stg abbrev|end stg abbrev|ZFA:####
        (old term )                             (new term ) 

     Excel won't put an ending "|", later script will add that.
   
   4) Generate                                            
      o  stageKeyword.csv exported from Thisse template on FogBUGZ
         case 362.
  
   5) Load test database 
      
      Change loadAO.sql to "commit work", gmake.
      At TARGET dir, copy over AO_translation.unl and 
      stageKeyword.csv.
        
	% loadMaster.sh 
 
        Note: At the end of loadMaster.sql we run check_annotation.sql 
        again to catch any omissions. If anything outputed in 
        annotationViolates.err, send to curators. 
        Then either run the following function to adjust one by one:   
 
	execute function xpat_annot_adjust(oldAnatZdbId, startStgZdbId, endStgZdbId, newAnatZdbId)
   
        Or create the AO_translation.unl file as the above format and run make_annot_translation.sql.


   6) Load Production
      At zfindb TARGET dir (MUST be user informix), copy over
      (anatomy.obo,) AO_translation.unl and stageKeyword.csv.

        % parseOBO.pl <path_to_anatomy.obo>

	% loadMaster.sh

      Currently for statistics, we make notes from the SQL output. When it gets regular and stable, we should automate this :
          how many new cell terms
          how many new anatomy terms  
          how many stages changed
          how many new definitions, updated definitions
          how many more relationships



Postload
---------

   Commit the anatomy.obo file, which is used for the load(normally with some corrections), into CVS. 
   Unload AO, refer to the first half of this file.
 

------------------------------
-- Future Improvement?
------------------------------
 o Generate and compare statistics 
 o Web interface for updates??
