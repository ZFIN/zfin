=======================================================
== README for data_transfer/Anatomy
=======================================================

This directory has a group of scripts for unload the AO from ZFIN to OBO file,
and a group of scripts for load the OBO file back into ZFIN to update the AO.

---------------------------------------------------
-- Unload AO
--------------------------------------------------

Scripts:
--------
  err_report.pl -- function reportErr($)

  anatitem_2_obo.pl -- unload anatomy and anatomy relationship to a obo file.

  stg_2_obo.pl -- unload stage information to a obo file.

  unloadAO.pl  -- master script. Generate and send zfin.obo to <!--|AO_EMAIL_CURATOR|-->, error to <!--|AO_EMAIL_ERR|-->

Execution:
----------
  To generate OBO for curators

	% gmake unload
     
  To generate OBO for OBO site
	
	% gmake unloadshare

  With both execution, the OBO file would be emailed to curators. Curators would re-save them in DagEdit to re-order the items, and commit the internal version into CVS, and send the external one to OBO site and collaborators. 

---------------------------------------------------
-- Load AO
--------------------------------------------------

Scripts:
--------

   parseOBO.pl -- parser, generates the .unl files for loading

   loadAO.sql -- big SQL, prepare and load AO to ZFIN. 

   make_annot_translation.sql -- unload AO_translation.unl, launch
			batch_xpat_annot_adjust() function.

   batch_xpat_annot_adjust.pl -- execute xpat_annot_adjust() function on 
			each row in anatitem_stg_change_tmp table.

   parse_stage_keywords.pl -- reads stageKeywords.csv from Thisse template,
			parse it into stageKeywords.unl for loading.

   check_thisse_keywords.sql -- pick up stageKeywords.unl, output problem
                        keywords after ZFIN AO got updated. 

   check_annotation.sql   -- check the expression annotation stage window 
                        with the anatomy stage window, output inconsistences to 
                        annotationViolates.err

   loadMaster.sh -- launch the load, then ajust xpat annotation, check Thisse
		    template and send problems to curators.		    
   
Execution:
----------

   It would be nice to automate this process, and just type "gmake load" and done, however, the free human editing in DAG edit or OBO edit is not going to be error free, which means testing is always needed.  

   1) Get the up-to-date anatomy.obo file from CVS

   2) Parse
      At a fresh test db, go to the TARGET directory:

  	% parseOBO.pl <path_to_anatomy.obo>

     Check STDOUT for error. Fix anaotmy.obo.
     
   3) Test load 
     At source dir, check out loadAO.sql, comment out "commit work",
     and test load.

	% dbaccess <db_name> loadAO.sql

     Check that
     o No SQL error. 

     o ls -l *.err
       check pub_incorrect.err, start_startInconsistent.err, 
       end_startInconsistent.err and end_endInconsistent.err.
       Normally, we have stage conflicts, hand it to curators,
       make correction and repeat the parsing and test load.

     Send annotationViolates.err content to Ceri & Melissa, 
     Ask for 
     o  AO_translation.unl with format

        ZFA:####|start stg abbrev|end stg abbrev|ZFA:####
        (old term )                             (new term ) 

     Excel won't put an ending "|", later script will add that.
   
   4) Generate                                            
      o  stageKeyword.csv exported from last Thisse sending
  
   5) Load test database (might skip)
      change loadAO.sql to "commit work", gmake.
      At TARGET dir, copy over anatomy.obo, AO_translation.unl and 
      stageKeyword.csv.
        
        % parseOBO.pl <path_to_anatomy.obo>

	% loadMaster.sh          

   6) Load Production
      At zfindb TARGET dir (has to be informix user), copy over
      (anatomy.obo,) AO_translation.unl and stageKeyword.csv.

        % parseOBO.pl <path_to_anatomy.obo>

	% loadMaster.sh

      Currently for statistics, we make notes from the SQL output. When it gets regular and stable, we should automate this :
          how many new terms
          how many stages changed
          how many new definitions, updated definitions
          how many more relationships

   Note: At the end of loadAO.sql we check annotation and so to have the translations on hand for loadMaster.sh. However, there could be omissions, thus we run check_annotation.sql again at the end of loadMaster.sh. If anything in annotationViolates.sql, send to curators. You could then either run the following function to adjust one by one:

      execute function xpat_annot_adjust(oldAnatZdbId, startStgZdbId, endStgZdbId, newAnatZdbId)
   
   Or create the AO_translation.unl file as the above format and run make_annot_translation.sql.
   

Postload
---------

   Commit the anatomy.obo file, which is used for the load(normally with some corrections), into CVS. 
   Unload AO, refer to the first half of this file.
 

------------------------------
-- Future Improvement?
------------------------------
 o Generate and compare statistics 
 o Web interface for updates??
