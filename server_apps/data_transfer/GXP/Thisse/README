
==========================
=== Thisse
===========================

--------------------
-- File collection
---------------------

   * Download data package (.sitx file) from ftp://ftp-igbmc.u-strasbg.fr/pub/Thisse/, use STUFFITS (www.stuffit.com) to expand the package. 
   * Use FileMaker Pro to open and export FileMake Pro Database files (listed below) into .csv files. Open files with account name "Thisse" and password "thisse". From File pulldown menu, choose Export, give names as defined below, use .csv extension. When exporting DATA_FRX, the default exporting columns might be of a wrong order, DO "Clear All", Then move columns till "date last modified". Make sure "digest" column is right after "library". For others, it is safe to use the default, just double check "date last modified" is the last column for exporting. The output character set should be Windows(ANSI).

	DATA_FRX->probes(.csv) 
	rel_authors->authors(.csv) 
	rel_expression->expression(.csv) 
	rel_images->images(.csv) 

            
   * Transfer all images and  probes.csv, images.csv, expression.csv, authors.csv files to one new directory, recommended name FR#_mmdd, # is the package number if given.

   * Copy all the executables to the same dir

-------------------
-- Spellcheck 
--------------------

   * ISPELL check for each .csv files, expression.csv normally needs some correction. 

	    >ispell -p ispell_common expression.csv

     You will be using and updating a common ispell dictionary. To enable update, 
		chmod u+w ispell_common
     and commit it back into cvs if you made any updates. 

   * In case of Thisse annotated (CB) loads, (otherwise, skip)
       - Run
		>/private/bin/rebol -sqw get_annotation_txt.r 

    	 which generates "annotation.txt" file, and checks for bad 
  	 apprearance of ":", and "null" in any annotation files. 

       - Correct the .txt file(s) that has violation.
       - ISPELL check the annotation.txt file and make corrections 
            in the .txt file. 

------------------------- 
-- Image processing
--------------------------

    $executables$:  thumbnail.sh, processImage.sh      
    $command$    :

	  > processImage.sh labname [release_type]

	  labname:                  Thisse / Talbot
          release_type: 	    cb    with annotation
          (in case of Thisse)   fr    without annotation
    
    $resulted files$:  images.dim	
    $description$ :
	    It creates Imagesdir/ and move all .jpg a(nd corresponding .txt files) into it. It does image reality check with images.csv file, if no missed entries reported, answer "y" to continue when it prompts, otherwise, answer "n" and solve the inconsistency with Curator, and launch the process again. 
	The second half of the program calls thumbnail.sh to generate thumbnail images, upon finish, it checks for completeness. Answer "y" to finish with cleanup if no missed images reported, otherwise, answer "n" to quit and investigate.


--------------------------------------------------
-- Preload processing: Parsing, Naming, Blasting
--------------------------------------------------

    $note$ : 
		- Update your test database and source the environment. The scripts would inherit environment from the running shell. 
        - Ask Peiran to update the ZFIN blast database, or run 
			  /research/zblastfiles/users/peirans/Scripts/ZFIN/processZFIN.pl 0
 
    $executables$:  parseThisse.pl  checkDups.sql nameClone.pl blast2tab.pl 
		    filterBlast.pl thisseData2Unl.sh

    $command$    :

	   > thisseData2Unl.sh <your_db_name>

    $result files$:   
			probes.unl
			expression.unl 
			keywords.unl 
			images.unl 
			authors.unl 
			(acc_imClone.unl)
			(is_gene.unl)
			(blast2zfin.scnd)
	
    $description$ :
	    This master script calls parseThisse.pl and  nameClone.pl first, and generates a group of .unl file for loading. If there is unknown accession number, it will blast the accessions against ZFIN sequence database, use blast2tab.pl to convert the results to table format while filter out matches with <90% identity. The blast2zfin.fst file is then feeded into filterBlast.pl which exams the results and write qualified matches into is_gene.unl, and the rest to blast2zfin.scnd for manual curation. 

----------------
-- Loading
----------------

    $note$ : Test load on your database and almostdb before running on production. 
    $executables$: pre_gxp_load.sql gxp_load_func.sql post_gxp_load.sql
		   gxp_load_quantity_check.sql load_gxp.sh get_fr_gene_list.sql
		   getStat4Load.sql

    $command$ :

	  > load_gxp.sh <db_name> <lab_name> [release_type]

          lab_name   :     Thisse /Talbot
          release_type:    fr/cb

	$result files$  :  (FR only)
		  fr_gene.txt     FR# to ZFIN gene, cDNA translation table
		  statistics.txt  
       Send the two files to Ceri. 

    $description$ :
	  This master script first calls pre_gxp_load.sql to load the files into a set of tables and conduct quality check with zfin db. Errors are written to separate .err file. The script would exit on any error with temp tables cleaned up. (Error file description is provided below, read first one at least!) Upon success, it executes the gxp_load_func.sql and then uses the SPL function with a set of predefined parameters to load the data into database. If the load fails with exit value "1", check /tmp/gxp_load_exception for reasons. If the load successes with "0", the gxp_load_quantity_check.sql would generate related table contents comparison report. Please go over the report. If everything looks good, answer yes to the prompt to clean up all the temporary tables, otherwise, keep the table for diagnose and run post_gxp_load.sql later.


----------------
-- Post load
----------------

    $note$ : Thisse FR ZGC only 
    $executables$: /research/zusers/peirans/GXP/Thisse/redundance_check.sh
		copy it to your execution directory where probes.unl, blast2tab.unl and filterBlast.pl reside.
    $command$ :

		> redundance_check.sh <dbname>

	$result files$  : 	
			is_gene.unl
			blast2zfin.scnd
	 
    $description$ :
		Start from FR5, we run BLAST for redundant check after Thisse FR ZGC data is loaded. This effort is expected to be replaced by ZFIN redundance pipeline in Feb/2005, so it is not committed into CVS. Please send is_gene.unl and blast2zfin.scnd to Ceri after the execution. 


---------------------
-- Appendix
---------------------

 Do a "ls -l *.err";
    1) exist_same_xpat_experiment_from_directsub.err: 
		When there exists an expression experiment record using the same probe and is also from direct submission, it is highly possible to be from the same submission. Upon this error, check if the existing one has the same submission source, if yes, send to curator to contact the source for correction. Otherwise, ignore this error by commenting out the exit code from load_gxp.sh after all the other errors are fixed. 
		We have seen this error a couple times, it either requires a deletion of misplaced expression data or a switch of the expression data from one clone to another. Peiran has a small SQL file to deal with this, and will create a SPL routine into CVS.
 
    2) unknown_probelib.err  : there might be an alias library name in zfin    

    3) prb_without_xpat.err  : ask curator if we want to only load clone info or delete the entry.

    4) dup_xpat.err : xpat data with same clone name, same start and end stage, delete one. 

    5) xpat_stg_unknown.err: stage not in zfin stage table. (not for thisse but talbot)

    6) keywords.undef.err: keywords not in anatomical dictionary.

    7) keywords_stgerr.err: fail anatitem_overlaps_stg_window check

    8) kwd_xpat_unconsistent.err: keyword's stage not in xpat file

    9) fimg_preparation_unknown.err

    10) fimg_view_unknow.err

    11) img_xpat_unconsist.err: image stage not in xpat file

    12) suthor_dup.err: duplicate entry in author file

    13) non_zfin_author.err: the author doesn't have an existing ZFIN person record

    *) xpatstg_withno_kwd_img.del: There are default stages defined in Thisse template. Occasionally some are left in with no data added. The script identify them by exp_found as "t", comments as "No comments", no keywords and no images. Those are not loaded.  

